{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, re, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras import layers, models, optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = r'C:\\Users\\Prashant\\Desktop\\seg_train\\seg_train'\n",
    "test_dir = r'C:\\Users\\Prashant\\Desktop\\seg_test\\seg_test'\n",
    "pred_dir = r'C:\\Users\\Prashant\\Desktop\\seg_pred'\n",
    "labels = sorted(os.listdir(train_dir))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11230 images belonging to 6 classes.\n",
      "Found 2804 images belonging to 6 classes.\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                           shear_range = 0.2,\n",
    "                           zoom_range = 0.2,\n",
    "                           horizontal_flip=True,\n",
    "                           validation_split=0.2)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "                        train_dir,\n",
    "                        shuffle=False,\n",
    "                        class_mode=\"categorical\",\n",
    "                        target_size=(150,150),\n",
    "                        batch_size = 16,\n",
    "                        subset='training')\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "                        train_dir,\n",
    "                        shuffle=False,\n",
    "                        class_mode=\"categorical\",\n",
    "                        target_size=(150,150),\n",
    "                        batch_size = 16,\n",
    "                        subset='validation')\n",
    "\n",
    "tst_aug = ImageDataGenerator(rescale=1./255)\n",
    "test_gen = tst_aug.flow_from_directory(\n",
    "                        test_dir,\n",
    "                        shuffle=False,\n",
    "                        class_mode=\"categorical\",\n",
    "                        target_size=(150,150),\n",
    "                        batch_size = 16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense,Dropout,Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3 = InceptionV3(include_top= False, input_shape=(150,150,3))\n",
    "\n",
    "for layer in inceptionV3.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 3, 3, 2048)\n"
     ]
    }
   ],
   "source": [
    "last_layer = inceptionV3.get_layer('mixed9')\n",
    "\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Flatten()(last_output)\n",
    "x = tf.keras.layers.Dense(units = 1024, activation = tf.nn.relu)(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense  (6, activation = tf.nn.softmax)(x)\n",
    "\n",
    "model = tf.keras.Model( inceptionV3.input, x)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=1,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.25,\n",
    "                                            min_lr=0.000003)\n",
    "\n",
    "model.compile(optimizer= 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "702/702 [==============================] - 674s 960ms/step - loss: 0.3553 - accuracy: 0.8742 - val_loss: 0.3454 - val_accuracy: 0.8663\n",
      "Epoch 2/30\n",
      "702/702 [==============================] - 672s 957ms/step - loss: 0.2752 - accuracy: 0.8965 - val_loss: 0.3222 - val_accuracy: 0.8852\n",
      "Epoch 3/30\n",
      "702/702 [==============================] - 671s 956ms/step - loss: 0.2260 - accuracy: 0.9147 - val_loss: 0.2887 - val_accuracy: 0.8973\n",
      "Epoch 4/30\n",
      "702/702 [==============================] - 673s 958ms/step - loss: 0.2065 - accuracy: 0.9219 - val_loss: 0.2845 - val_accuracy: 0.9001\n",
      "Epoch 5/30\n",
      "702/702 [==============================] - 670s 954ms/step - loss: 0.1774 - accuracy: 0.9317 - val_loss: 0.2775 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "702/702 [==============================] - 673s 959ms/step - loss: 0.1662 - accuracy: 0.9369 - val_loss: 0.3284 - val_accuracy: 0.9016\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18e08ef7d88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data = valid_generator, \n",
    "    callbacks=EarlyStopping(monitor='val_loss', mode='min',verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 139s 738ms/step - loss: 0.2959 - accuracy: 0.9083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29586097598075867, 0.9083333611488342]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7301 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "pred_aug = ImageDataGenerator(rescale=1./255)\n",
    "pred_gen = pred_aug.flow_from_directory(\n",
    "                        pred_dir,\n",
    "                        shuffle=False,\n",
    "                        class_mode=\"categorical\",\n",
    "                        target_size=(150,150),\n",
    "                        batch_size = 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.5239508e-01, 2.4686996e-03, 1.8252898e-02, 1.8092648e-03,\n",
       "        1.7840877e-04, 2.4895692e-02],\n",
       "       [7.7899938e-07, 3.3279840e-04, 4.5247074e-02, 9.5439827e-01,\n",
       "        1.8944007e-05, 2.0044527e-06],\n",
       "       [2.6867363e-01, 2.1079801e-05, 2.5055872e-04, 1.5427085e-04,\n",
       "        1.6074962e-05, 7.3088437e-01],\n",
       "       ...,\n",
       "       [4.7736335e-09, 1.1178713e-06, 3.9310911e-04, 9.9955004e-01,\n",
       "        5.5650471e-05, 5.4621103e-09],\n",
       "       [2.5769602e-13, 1.0000000e+00, 9.6019748e-11, 7.4891927e-17,\n",
       "        4.2506138e-15, 7.1755086e-13],\n",
       "       [4.9864808e-05, 3.2543945e-10, 8.3076550e-08, 8.1665757e-11,\n",
       "        3.8515666e-11, 9.9995005e-01]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.predict(pred_gen)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Prashant\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: imgintelclass.model\\assets\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "model.save('imgintelclass.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(results,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 5, ..., 3, 1, 5], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=pred_gen.filenames\n",
    "res=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seg_pred\\10004.jpg</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seg_pred\\10005.jpg</td>\n",
       "      <td>mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seg_pred\\10012.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seg_pred\\10013.jpg</td>\n",
       "      <td>mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seg_pred\\10017.jpg</td>\n",
       "      <td>mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7296</th>\n",
       "      <td>seg_pred\\9988.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7297</th>\n",
       "      <td>seg_pred\\9992.jpg</td>\n",
       "      <td>forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7298</th>\n",
       "      <td>seg_pred\\9993.jpg</td>\n",
       "      <td>mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>seg_pred\\9995.jpg</td>\n",
       "      <td>forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300</th>\n",
       "      <td>seg_pred\\9996.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7301 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Filename Predictions\n",
       "0     seg_pred\\10004.jpg   buildings\n",
       "1     seg_pred\\10005.jpg    mountain\n",
       "2     seg_pred\\10012.jpg      street\n",
       "3     seg_pred\\10013.jpg    mountain\n",
       "4     seg_pred\\10017.jpg    mountain\n",
       "...                  ...         ...\n",
       "7296   seg_pred\\9988.jpg      street\n",
       "7297   seg_pred\\9992.jpg      forest\n",
       "7298   seg_pred\\9993.jpg    mountain\n",
       "7299   seg_pred\\9995.jpg      forest\n",
       "7300   seg_pred\\9996.jpg      street\n",
       "\n",
       "[7301 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
